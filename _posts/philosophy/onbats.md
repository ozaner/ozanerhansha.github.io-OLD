While I agree with Nagel's sentiment that reductionist models don't accurately explain why we think there is this 'different' sort of phenomenon called consciousness experience, I disagree with his hand-wavy refusal of these reductionist models.

Nagel seems to believe that consciousness is *truly* of a different sort and not just that humans *intuitively* think this. His basis for this implicit claim is his intuition, as far as I can see at least.

Ultimately this paper seems to be Nagel asserting his beliefs on the singularity and specialness of the illusion I claim to be consciousness.

*Paragraph 3*<br>
He simply asserts consciousness phenomena being something that can be attributed to many creatures and that it is extremist to think otherwise. What consciousness he is referring to? To ability to feel pain? Goal-oriented action? Language and communication with others?

*Paragraph 4*<br>
This 'subjective' experience he speaks of seems to be simply the parts he doesn't understand of the brain and how its mish-mash of competing neural networks constructs an illusion of self.

In this paragraph he says that these models couldn't possibly be correct as they imply robots and automaton could feel even though 'they feel nothing.' It's clear he already has a preconceived notion of consciousness. The intuitive (read: not rigorous in any way) one that says humans are consciousness, and robots are not. The one that says humans and animals shouldn't suffer because we find it repugnant for social and evolutionary reasons.

Also regarding
>"...fundamentally an organism has conscious mental
states if and only if there is something that it is to be that organismâ€”something it is like for the
organism."

You can't get more hand-wavy than that. I don't blame Nagel, it's hard to formalize something that is claimed to be unformalizable by current standards. But this fact should highlight why Nagel ought to think twice about posing his argument as anything but an intuitive observation.

*Paragraph 5*<br>
It seems that Nagel is just rephrasing this intuitive idea of there being something 'other' to consciousness as something 'physicalist theory' hasn't accounted for yet.

*Paragraph 8*<br>
*Do* bats have experience? What the hell are we talking about Nagel? Do I think they think about they're mortality? Think about how mad their wife will be when they come home from hunting too late? (I'm being only partially facetious here). What is this experience you keep asserting we have? Something different from that of an automaton or a worm or a bee or maybe even a rock. It seems that all the premises of this argument are loosely defined *intuitive* concepts that we are applying in nonsensical ways.

*Blah*<br>
Nagel speaks of not being able to know the facts of being a bat unless we are in their shoes. But we can't 'be in their shoes'. It's like asking what would it be like if a shoe was a rock. Well now its a rock. It doesn't have some independent soul or essence that can be transplanted and thus can appreciate the difference between being a shoe and rock. They are just different *physical* and *chemical* systems. More to the point, its like asking "what would it be like if this algorithm was actually this algorithm." All brains and humans and selves are particles that follow the laws of particle physics. Their function can be described as such. That is, unless you believe in something immaterial based on the evidence of... your intuition? I would rather believe in the most precise experiments ever performed than even the collective intuition of human society.

Qualia doesn't exist.
