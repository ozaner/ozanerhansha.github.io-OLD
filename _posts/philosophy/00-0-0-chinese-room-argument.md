---
layout: post
title: On the Chinese Room Argument
date: 2019-02-11
tags: philosophy artificial-intelligence computer-science
---
<!-- On Searle's 'Minds, Brains, and Programs' -->
John Searle's Chinese room argument is a staple in the discussion of the philosophy of artificial intelligence. Described in his seminal paper ['Minds Brains, and Programs'](https://www.law.upenn.edu/live/files/3413-searle-j-minds-brains-and-programs-1980pdf) it, at least at first glance, appears to sum up our intuitive apprehensions in ascribing the seemingly rich qualia present in human experience to 'mere symbol manipulators' as Searle puts it. That said, it is in my view, and the view of many other scientists and philosophers, that the argument is deeply flawed in a variety of ways. Below I will detail 3 of my own objections to it.

<!--more-->

## Objection 1: Misleading Analogy
It seems like Searle poses the Chinese room argument to show how 'ridiculous' considering a man inside a room manipulating, what are to him, meaningless symbols constitutes consciousnesses. There are two main problems with this posing of the argument:

#### Complexity of such a Program
Searle phrases the Chinese room as some simple input output box that would have the operator manipulate a couple of symbols and return some output. This is a vast and naïve understatement of the complexity such a program would have. For this to be a reasonable scenario that man would either have to manipulate symbols many times greater than the speed of light (something which makes no physical sense) or perhaps have a whole team of billions of men only going at a significant fraction of the speed of light (more plausible but obviously ridiculous).

Now to this you might object, "yeah but *in principle* we could right?" Well sure, *in principle* we could, and *in principle* we could simulate entire universes, alternate histories of earth, brute force a cure for cancer and so on by just manipulating symbols. But at this point, the analogy Searle tries to make breaks down and is no more as convincing as simply stating "machines can't be conscious".

#### The Human Mind is a Machine
However, even more pressing is the neurological objection. Searle makes this argument stating that the operator of the Chinese room doesn't understand Chinese, and that he is simply following instructions. This is a fair point, but if we are to accept it at face value we have to do the same for the innerworkings of our own minds. I imagine Searle would think that he in fact understands English, but considering all his mental processes boil down to the statistical processes of neurons firing to a particular influx of inputs via his senses, and nothing more, I would ask what differentiates him from a computer whose inner process are also statistical processes of neurons firing to a particular influx of inputs? Is it that one is made of flesh and the other of matrix multiplies and non-linear functions? That one is borne of natural selection and the other of man?

Is it that my reductionist view is unsatisfactory? If so, why doesn't the room as a whole understand Chinese? Certainly the parts of the room/brain (i.e. the physically impossible men/neurons) don't 'understand' what they are doing, right? And yet the structure as a whole does as Searle points out. So unless there is something specific to humans other than a capability to reason about the world and provide responses to it, the brain and the machine are indistinguishable no? If not then there's something else there. Something... ephemeral. Something... bullshit.

This 'something' is the intuition that we have a spirit or soul, or whatever you'd like to call it. And it's nothing but that: an intuition. Just a product of our evolved psychology. To be sure, such an intuition is useful for man to have, so that we were not just a pack of gloomy and existential cavemen back in the hunter-gatherer days. But usefulness is not our goal in discussing such a concept, and certainly not the goal of philosophy.

## Objection 2: Syntax is not Semantics
Searle's main point is trying to convince the reader that:
1. Syntax is not sufficient for semantics
2. Programs are entirely characterizes by their syntax
3. Human mental states have semantic aspects
4. Therefore, computers cannot be minds

And this is where the fundamental problem arises again: "what is semantics, and why can't a computer have it?" What Searle and all others who come up  with fanciful and misleading descriptions of Chinese rooms, philosophical zombies, etc. are toeing around is the age old question of dualism vs. physicalism. If you believe in physicalism then it is necessarily the case that there can be nothing 'special' to a human brain that distinguishes it from a computer. This is an empirically, and even further mathematically, irrefutable fact.

However, you can still save your belief that humans are somehow different or 'special' and have semantic mental states in a way computers can't if you believe in the immaterial. And more specifically that humans have some ephemeral semantic 'object' tied to their mental states. While this solves the problem it is of course just a show stopping 'just because' type of belief that has no basis in observable fact (duh that's its whole premise). But at this point we may as well posit immaterial solutions to all our philosophical problems.

## Objection 3: Searle doesn't know what a Turing Machine is
Searle's Chinese room argument unlike other philosophical arguments, is based on a mathematical theory. In particular the theory of Turing machines. This will be his downfall as he clearly does not understand them beyond simple 'symbol manipulators'.

[Richard Yee's Paper on the matter.](https://chineseroom.info/doc/Angels-Dancing-Chinese-Room_v13_2016.pdf)

The gist of it is that Searle conflates the *universal Turing machine* with the more general *Turing machine*. Searle doesn't realize that the computer, the universal Turing machine, is Seale himself in the box. The Turing machine that actually does the Chinese processing is the one he is simulating by interpreting the English instructions given to him. Those English rules and the Chinese input together form the input to Searle, not just the Chinese.

So when he implements the Chinese translating program he is doing symbolic manipulation, but when he is interpreting the English rules to do that manipulation, he is using his 'intuition' and 'human understanding' to do so. Searle can only introspect on the universal computation he is performing, and the argument only focuses on this purely symbolic computation. But the actual computation of interest, the simulated Turing machine responding to Chinese, is not accessible to Searle. He wouldn't be able to know if it was processing inputs the way a real Chinese speaker might.

Yee boils down the argument to this:
> 1. If computation alone were sufficient for human understanding of Chinese, then in principle there would be a program for it.
> 2. Let Searle execute such a program exactly as a computer would.
> 3. In so doing, Searle detects no human understanding of Chinese. Hence, it does not occur in the room.

#### The Systems Reply
In this light the systems reply is the idea that what has the understanding of Chinese is the simulated Turing machine (the program). Searle could not be aware of this understanding as he is just a middleman, no different than a transistor or neuron.

<!-- Searle's reply:
> Actually I feel somewhat embarrassed to give even this answer to the systems theory because the theory seems to me so implausible to start with. The idea is that while a person doesn’t understand Chinese, somehow the conjunction of that person and bits of paper might understand Chinese. It is not easy for me to imagine how someone who was not in the grip of an ideology would find the idea at all plausible.

He is actually an idiot. -->

## Conclusion
It would seem to me that the only thing Searle's argument formalizes is our inherent and seemingly unshakeable bias that if consciousness is a thing, then only humans/biological entities can have it. It is unfounded and ignores the mechanical construction of ourselves and of everything in the universe.

It also ignores what Turing machines are and how computation works.
It is this lack of mathematical understanding by Searle that makes his argument patently and provably false unlike most other philosophical arguments. That is, unless we admit that his argument boils down to human minds are different just because.

<!-- The only way out of this issue is the belief in something immaterial inherent to all humans and while such a belief is certainly a panacea for the problems that plague philosophy, it is not exactly a satisfying one. -->

<!-- To be fair artificial neural networks weren't what they were back then. (Comment I made on sticky note but doesn't really apply since Searle is still alive and stands by this BS. Also some contemporaries buy it too.) -->