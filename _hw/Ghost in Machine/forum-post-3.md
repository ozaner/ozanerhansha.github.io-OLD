## Forum Post 3
What questions would you use if you performed a Turing test, and why?

If I were the interrogator in a Turing test I wouldn't use questions of the following sort (this isn't exhaustive):
- Jokes or puns. This is a classic type of question to use in Turing tests but it is not impossible, nor even implausible, that we could develop a language parsing AI that could make sense of such wordplay and even analyze it for sentiment. We already have the rudiments of such systems today.
- "Is this sentence false?". This won't work either as these overplayed logical paradoxes won't 'crash the computer' or anything of the sort. A well programmed Turing test taker would be able to identify these paradoxes and simply respond with "What am I a logician?" or "the truth value of that statement is undefined" depending on what kind of person this program is trying to imitate.
- "What is life?" or "Who made you?". Again, the program is not trying to imitate a being of perfect knowledge but a regular old human. It should answer these big existential questions the same way you or I might. Maybe it would pause for a while and say something that sounds profound but is ultimately trite: "It's about the journey." or maybe give a frank answer like "God did, I suppose" or "natural selection I guess." It may even respond with a snarky "Nice one, that'll separate man from machine."
- "Write me a poem/song" or "Draw me a picture". Again we are imitating humans and considering there are AIs that can and have created better poetry, art and music than me, I think they'll be fine. 'Creativity' as we may na√Øvely think of it is certainly not limited to humans.

While I think imitating a human is definitely possible, there may be certain questions that are harder to develop systems to answer than others. A good line of questioning may ask the program/human about their life, their career, their hopes, funny stories about themselves, etc. Not only may those things be hard for a program to generate to any detail, but making sure they are all consistent (and maybe not too consistent to account for the foggy and constructed human memory) may prove even harder.

- "What was your favorite memory from Elementary School."
- "What are your hobbies."
- [In response] "Oh really? Well tell me more about [x]."
- [Still on the topic of x] "Oh but what about [y]?"
- "When did you start getting into [x]?"
- "Hey that's kinda like how you were [x] in elementary school right?"

And so on. Ultimately AIs have yet to display decent storytelling abilities besides writing short structured pieces like news articles. Hopefully one day they can write compelling narratives on the order of Harry Potter or the like. Until then, this lacking may serve a good way to distinguish them from humans.

The problem of AIs writing stories is a massive one. Making art, poetry, songs, etc. is easy enough it conceptualize. But the fine detail and structure of the output is far more important to a story than to art (i.e. one pixel being slightly more blue doesn't matter, but a sentence that doesn't follow from another smoothly does matter). Since there is such a need for long term memory, a mastery of not just language but prose, and a understanding of why humans like different stories (i.e. data on human sentiment maybe even at the level of the brain), I don't think our current machine learning paradigm can hope to solve this problem.
